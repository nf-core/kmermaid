docker.enabled = true

timeline {
  enabled = true
  file = "${params.tracedir}/execution_timeline.html"
}
report {
  enabled = true
  file = "${params.tracedir}/execution_report.html"
}
trace {
  enabled = true
  file = "${params.tracedir}/execution_trace.txt"
}
dag {
  enabled = true
  file = "${params.tracedir}/pipeline_dag.svg"
}

params {
  // Pipeline Options
  read_pairs = "data/*{1,2}.fastq.gz"
  read_singles = false
  samplescsv = false
  readPaths = false
  singleEnd = false
  fasta = false
  srr = false
  molecules ='dna,protein,dayhoff'
  ksizes = '21,27,33,51'
  log2_sketch_sizes = '10,12,14,16'

  // Boilerplate options
  outdir = './results'
  name = false
  multiqc_config = "$baseDir/assets/multiqc_config.yaml"
  email = false
  plaintext_email = false
  monochrome_logs = false
  help = false
  maxMultiqcEmailFileSize = 25.MB
  igenomes_base = "./iGenomes"
  tracedir = "${params.outdir}/pipeline_info"
  awsqueue = false
  awsregion = 'eu-west-1'
  igenomesIgnore = false
  custom_config_version = 'master'
  custom_config_base = "https://raw.githubusercontent.com/nf-core/configs/${params.custom_config_version}"
  hostnames = false
  config_profile_description = false
  config_profile_contact = false
  config_profile_url = false
}

process.container = 'czbiohub/nf-kmer-similarity:olgabot-dayhoff'

profiles {

  local {
    process.executor = 'local'
  }

  docker {
    process.executor = 'local'
    docker.enabled = true
  }

  aws {
    process.executor = 'awsbatch'
    process.queue = 'nextflow'
    executor.awscli = '/home/ec2-user/miniconda/bin/aws'
    workDir = 's3://czb-nextflow/work'
    docker.enabled = true
    params.tracedir = './'
  }
  test {
  params {
    // Input data
    samples = 'testing/samples.csv'
    fastas = 'testing/fastas/*.fasta'
    ksizes = '3,9'
    log2_sketch_sizes = '2,4'
    molecules = 'dna,protein'
    read_pairs = 'testing/fastqs/*{1,2}.fastq.gz'
    sra = "SRP016501"
    }
  }
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']


aws {
	region = 'us-west-2'

    client {
        maxConnections = 20
        connectionTimeout = 10000
        uploadStorageClass = 'INTELLIGENT_TIERING'
        storageEncryption = 'AES256'
    }
}

// Command to not over-ask for more resources than are on the computer
// Useful for test environments
// Function to ensure that resource requirements don't go beyond
// a maximum limit
// From https://github.com/nextflow-io/nextflow/issues/640
def check_max(obj, type) {
  if(type == 'memory'){
    try {
      if(obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if(type == 'time'){
    try {
      if(obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if(type == 'cpus'){
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}

process {

  cpus = { check_max( 1 * task.attempt, 'cpus') }
  memory = { check_max( 8.GB * task.attempt, 'memory') }
  time = { check_max( 2.h * task.attempt, 'time') }


  maxRetries = 3
  maxErrors = '-1'

  // Resource requirements
  withName: sourmash_compare_sketches {
    memory = { check_max( 512.GB * task.attempt, 'memory') }
    cpus = 1
  }
  withName: sourmash_compute_sketch {
    memory = { check_max( 4.GB * task.attempt, 'memory') }
    cpus = 1
  }

}
